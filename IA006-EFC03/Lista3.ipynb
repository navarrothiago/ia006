{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_teste = sio.loadmat('dados_teste.mat')\n",
    "dados_treino = sio.loadmat('dados_treinamento.mat')\n",
    "dados_valid = sio.loadmat('dados_val.mat')\n",
    "\n",
    "x_teste = np.array(dados_teste[\"Xt\"])\n",
    "y_teste =  np.array(dados_teste[\"yt\"])\n",
    "x_treino =  np.array(dados_treino[\"X\"])\n",
    "y_treino =  np.array(dados_treino[\"y\"])\n",
    "x_valid =  np.array(dados_valid[\"Xval\"])\n",
    "y_valid =  np.array(dados_valid[\"yval\"])\n",
    "\n",
    "\n",
    "#\n",
    "teste_df=pd.DataFrame(x_teste,columns=['x1','x2'])\n",
    "teste_df['y']=y_teste\n",
    "treino_df=pd.DataFrame(x_treino,columns=['x1','x2'])\n",
    "treino_df['y']=y_treino\n",
    "valid_df=pd.DataFrame(x_valid,columns=['x1','x2'])\n",
    "valid_df['y']=y_valid\n",
    "total_df=pd.DataFrame(x_teste,columns=['x1','x2'])\n",
    "total_df['y']=y_teste\n",
    "total_df.append(treino_df, ignore_index=True)\n",
    "total_df.append(valid_df, ignore_index=True)\n",
    "\n",
    "print(teste_df.describe())\n",
    "print(treino_df.describe())\n",
    "print(valid_df.describe())\n",
    "print(total_df.describe())\n",
    "print(total_df.hist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelizer(input,positive_label,negative_label):\n",
    "    input_intern=input\n",
    "    for i in range(0,len(input)):\n",
    "        if input[i]==positive_label:\n",
    "            input_intern[i]=1\n",
    "            \n",
    "        if input[i]==negative_label:\n",
    "            input_intern[i]=0            \n",
    "    return input_intern\n",
    "\n",
    "y_teste_rn=labelizer(y_teste,1,-1)\n",
    "y_treino_rn=labelizer(y_treino,1,-1)\n",
    "y_valid_rn=labelizer(y_valid,1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cria_mlp(neuronios,otimizador='Adam',ativacao='relu'):\n",
    "    rede_neural=Sequential()\n",
    "    rede_neural.add(Dense(neuronios, input_dim=2, activation=ativacao))\n",
    "    rede_neural.add(Dense(1, activation='sigmoid'))\n",
    "    # Para entropia cruzada\n",
    "    rede_neural.compile(loss='binary_crossentropy', optimizer=otimizador, metrics=['accuracy'])\n",
    "    # Para o erro quadrático médio\n",
    "#     rede_neural.compile(loss='mean_squared_error', optimizer=otimizador, metrics=['accuracy'])\n",
    "    return rede_neural\n",
    "\n",
    "def mostra_grafico_custo(historico):\n",
    "    plt.plot(historico.history['loss'])\n",
    "    plt.plot(historico.history['val_loss'])\n",
    "    plt.title('Custo')\n",
    "    plt.ylabel('Custo')\n",
    "    plt.xlabel('Epoca')\n",
    "    plt.yscale(\"log\")\n",
    "    plt.legend(['Treino', 'Validacao'], loc='upper left')\n",
    "    plt.show()\n",
    "def mostra_grafico_accuracy(historico):\n",
    "    plt.plot(historico.history['accuracy'])\n",
    "    plt.plot(historico.history['val_accuracy'])\n",
    "    plt.title('Acurácia')\n",
    "    plt.ylabel('Acurácia')\n",
    "    plt.xlabel('Epoca')\n",
    "    plt.yscale(\"log\")\n",
    "    plt.legend(['Treino', 'Validacao'], loc='upper left')\n",
    "    plt.show()\n",
    "def mostra_mensagem(historico):\n",
    "    print(\"Custo final treino:\")\n",
    "    print(historico.history['loss'][-1])\n",
    "    print(\"Custo final validação:\")\n",
    "    print(historico.history['val_loss'][-1])\n",
    "    print(\"Acurácia final treino:\")\n",
    "    print(historico.history['accuracy'][-1])\n",
    "    print(\"Acurácia final validação:\")\n",
    "    print(historico.history['val_accuracy'][-1])\n",
    "def plot_decision_boundary(X, y, model, steps=100, cmap='Paired'):\n",
    "    cmap = plt.get_cmap(cmap)\n",
    "\n",
    "    # Define region of interest by data limits\n",
    "    xmin, xmax = X[:,0].min() - 1, X[:,0].max() + 1\n",
    "    ymin, ymax = X[:,1].min() - 1, X[:,1].max() + 1\n",
    "    x_span = np.linspace(xmin, xmax, steps)\n",
    "    y_span = np.linspace(ymin, ymax, steps)\n",
    "    xx, yy = np.meshgrid(x_span, y_span)\n",
    "\n",
    "    # Make predictions across region of interest\n",
    "    labels = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    # Plot decision boundary in region of interest\n",
    "    z = labels.reshape(xx.shape)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.contourf(xx, yy, z, cmap=cmap, alpha=0.5)\n",
    "\n",
    "    # Get predicted labels on training data and plot\n",
    "    train_labels = model.predict(X)\n",
    "    colors = ['blue' if label == 1 else 'red' for label in y]\n",
    "    ax.scatter(X[:,0], X[:,1], s=7, c=colors, cmap=cmap, lw=0)\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "def aplica_threshold(y,threshold):\n",
    "    y_temp=y.copy()\n",
    "    for i in range(0,len(y)):\n",
    "        if y[i]>=threshold:\n",
    "            y_temp[i]=1\n",
    "        else:\n",
    "            y_temp[i]=0\n",
    "    return y_temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Letra a\n",
    "epocas=5000\n",
    "tamanho_batch=100\n",
    "neuronios=40\n",
    "#Teste 1 ReLu Adam\n",
    "print(\"Teste 1: Relu Adam\")\n",
    "rede_neural=cria_mlp(neuronios,otimizador='Adam',ativacao='relu')\n",
    "#Rede com as labels alteradas\n",
    "historico=rede_neural.fit(x_treino, y_treino_rn,validation_data=(x_valid,y_valid_rn), epochs=epocas, batch_size=tamanho_batch, verbose=0)\n",
    "mostra_grafico_custo(historico)\n",
    "mostra_grafico_accuracy(historico)\n",
    "mostra_mensagem(historico)\n",
    "\n",
    "#Teste 2 Relu Sgd\n",
    "print(\"Teste 2: Relu Sgd\")\n",
    "rede_neural = cria_mlp(neuronios,otimizador='sgd',ativacao='relu')\n",
    "#Rede com as labels alteradas\n",
    "historico=rede_neural.fit(x_treino, y_treino_rn,validation_data=(x_valid,y_valid_rn), epochs=epocas, batch_size=tamanho_batch, verbose=0)\n",
    "mostra_grafico_custo(historico)\n",
    "mostra_grafico_accuracy(historico)\n",
    "mostra_mensagem(historico)\n",
    "\n",
    "#Teste 3 Logistica Adam\n",
    "print(\"Teste 3: Logistica Adam\")\n",
    "rede_neural=cria_mlp(neuronios,otimizador='Adam',ativacao='sigmoid')\n",
    "#Rede com as labels alteradas\n",
    "historico=rede_neural.fit(x_treino, y_treino_rn,validation_data=(x_valid,y_valid_rn), epochs=epocas, batch_size=tamanho_batch, verbose=0)\n",
    "mostra_grafico_custo(historico)\n",
    "mostra_grafico_accuracy(historico)\n",
    "print(max(historico.history['val_loss']))\n",
    "mostra_mensagem(historico)\n",
    "\n",
    "#Teste 2 Logistica Sgd\n",
    "print(\"Teste 4: Logistica Sgd\")\n",
    "rede_neural = cria_mlp(neuronios,otimizador='sgd',ativacao='sigmoid')\n",
    "#Rede com as labels alteradas\n",
    "historico=rede_neural.fit(x_treino, y_treino_rn,validation_data=(x_valid,y_valid_rn), epochs=epocas, batch_size=tamanho_batch, verbose=0)\n",
    "mostra_grafico_custo(historico)\n",
    "mostra_grafico_accuracy(historico)\n",
    "mostra_mensagem(historico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Letra b\n",
    "epocas=5000\n",
    "tamanho_batch=100\n",
    "rede_neural = cria_mlp(40,otimizador='sgd',ativacao='relu')\n",
    "#Rede com as labels alteradas\n",
    "historico=rede_neural.fit(x_treino, y_treino_rn,validation_data=(x_valid,y_valid_rn), epochs=epocas, batch_size=tamanho_batch, verbose=0)\n",
    "\n",
    "plot_decision_boundary(x_treino,y_treino_rn,rede_neural,steps=1000,cmap='RdBu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Letra c\n",
    "print(rede_neural.evaluate(x_teste, y_teste_rn))\n",
    "y=rede_neural.predict(x_teste)\n",
    "print(confusion_matrix(aplica_threshold(y,0.5),y_teste_rn))\n",
    "tn, fp, fn, tp = confusion_matrix(aplica_threshold(y,0.5),y_teste_rn).ravel()\n",
    "print(\"Erro Percentual:\")\n",
    "print((fp+fn)/(tn+fp+fn+tp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuronios=[10,20,40,80,160,320]\n",
    "# neuronios=['10','20']\n",
    "epocas=5000\n",
    "tamanho_batch=200\n",
    "#ENTENDER MELHOR COMO ESSA VARIAÇÃO INFLUENCIA A PARADA\n",
    "variacao=0.00001\n",
    "paciencia=200\n",
    "relatorio=pd.DataFrame(columns=['Neuronios','Acurácia Treino','Acurácia Validação'])\n",
    "k=-1\n",
    "for i in neuronios:\n",
    "    k+=1\n",
    "    print(\"Numero Neuronios\")\n",
    "    print(i)\n",
    "    relatorio.loc[k,'Neuronios']=i\n",
    "    rede_neural = cria_mlp(int(i),otimizador='sgd',ativacao='relu')\n",
    "    es = EarlyStopping(monitor='val_accuracy', mode='max', min_delta=variacao,patience=paciencia, verbose=1)\n",
    "    mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=0, save_best_only=True)\n",
    "    historico=rede_neural.fit(x_treino, y_treino_rn,validation_data=(x_valid,y_valid_rn), epochs=epocas, batch_size=tamanho_batch,callbacks=[es,mc], verbose=0)\n",
    "    rede_neural=load_model('best_model.h5')\n",
    "#     O primeiro valor é o custo o segundo a acurácia\n",
    "    relatorio.loc[k,'Acurácia Treino']=rede_neural.evaluate(x_treino,y_treino_rn,verbose=0)[1]\n",
    "    relatorio.loc[k,'Acurácia Validação']=rede_neural.evaluate(x_valid,y_valid_rn,verbose=0)[1]\n",
    "print(relatorio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Teste, após este teste vimos que cada neurônio implementa o bias e de fato temos que colocar as lavbels corretamente 0,1.\n",
    "\n",
    "# teste=Sequential()\n",
    "# teste.add(Dense(1, input_dim=1, activation='sigmoid'))\n",
    "# teste.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "# x=np.array([0,1])\n",
    "# y=np.array([-1,1])\n",
    "# historico=teste.fit(x,y, epochs=100, batch_size=10)\n",
    "# print(teste.predict([0,1]))\n",
    "# for layer in teste.layers:\n",
    "#     print(layer.get_weights())"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
