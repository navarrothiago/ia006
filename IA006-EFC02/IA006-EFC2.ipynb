{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 1 - Classificação binária"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pdb;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.efc2 import csv_reader\n",
    "#%pycat efc2/csv_reader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = csv_reader.load_csv()\n",
    "#data.head(data.shape[0])\n",
    "\n",
    "data = data.drop(\"Unnamed: 0\", 1)\n",
    "data.head(data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(data)\n",
    "\n",
    "plot_rows = int(len(columns) / 2)\n",
    "if(len(columns) % 2 != 0):\n",
    "    plot_rows = plot_rows + 1\n",
    "\n",
    "print(plot_rows)\n",
    "fig1, axs = plt.subplots(plot_rows, 2, constrained_layout=True, figsize=(30,30))\n",
    "\n",
    "data.hist(ax=axs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(30, 30))\n",
    "plt.matshow(data.corr(), fignum=f.number)\n",
    "plt.xticks(range(data.shape[1]), data.columns, fontsize=14, rotation=45)\n",
    "plt.yticks(range(data.shape[1]), data.columns, fontsize=14)\n",
    "cb = plt.colorbar()\n",
    "cb.ax.tick_params(labelsize=14)\n",
    "plt.title('Correlation Matrix', fontsize=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(matrix_y, matrix_ye, matrix_phi):\n",
    "    matrix_error = matrix_y - matrix_ye\n",
    "    return -matrix_error.T.dot(matrix_phi)/len(matrix_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x é o phi_x.T\n",
    "def phi(x):\n",
    "    phi1 = np.ones((x.shape[0],1))\n",
    "    return np.concatenate((phi1, x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função custo\n",
    "def j_cross_entropy(targets, predictions, epsilon=1e-12):\n",
    "        \n",
    "    # só funciona se epsilon for maior que zero\n",
    "    assert(epsilon > 0)\n",
    "    \n",
    "    predictions = np.clip(predictions, epsilon, 1. - epsilon)\n",
    "    N = predictions.shape[0]\n",
    "    \n",
    "    #pdb.set_trace()\n",
    "    ce_when_y_1 = -np.sum(targets*np.log(predictions))/N\n",
    "    ce_when_y_0 = - np.sum((1-targets)*np.log(1-predictions))/N\n",
    "    ce = ce_when_y_1 + ce_when_y_0\n",
    "    \n",
    "    #print(\"y = 1 \", ce_when_y_1, \" y = 0\", ce_when_y_0, \" total = \", ce)\n",
    "    \n",
    "    return ce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fase de Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verificar se pode estar saturando sigmoide.\n",
    "matrix_phi = phi(preprocessing.scale(train.drop(\"label\", 1).values))\n",
    "\n",
    "# matrix com os dados \n",
    "matrix_y = train[\"label\"].values.reshape(train[\"label\"].values.shape[0], 1)\n",
    "\n",
    "matrix_phi\n",
    "#matrix_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "# Acha o w pelo método grandiente descendente e retorna, também, o custo em cada iteração\n",
    "def find_w(y_train, phi, alpha, iterations):\n",
    "    \n",
    "    # A dimensão da matrix w é número de atributos mais 1 x 1\n",
    "    w = np.random.rand(phi.shape[1], 1)\n",
    "\n",
    "    matrix_cost = np.zeros((iterations,))\n",
    "\n",
    "    for i in range(iterations):\n",
    "        z = phi.dot(w)\n",
    "        matrix_ye = 1 /(1 + np.exp(-z))\n",
    "\n",
    "        w = w - (alpha) * gradient_descent(y_train, matrix_ye, phi).T\n",
    "        matrix_cost[i] = j_cross_entropy(y_train, matrix_ye)\n",
    "        #matrix_cost[i] = log_loss(y_train, matrix_ye)\n",
    "\n",
    "    df_cost = pd.DataFrame(matrix_cost,columns=['cost'])\n",
    "    return w, df_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_w, df_cost = find_w(matrix_y, matrix_phi, 0.01, 10000)\n",
    "df_cost.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fase de Teste\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verificar se pode estar saturando sigmoide.\n",
    "matrix_phi_test = phi(preprocessing.scale(test.drop(\"label\", 1).values))\n",
    "\n",
    "# matrix com os dados de teste\n",
    "# recupera dados com rotulos label e reshape \n",
    "matrix_y_test = test[\"label\"].values.reshape(test[\"label\"].values.shape[0], 1)\n",
    "\n",
    "# calculando estimativa para todos os dados de teste com o w calculado anteriormente\n",
    "z = matrix_phi_test.dot(matrix_w)\n",
    "matrix_ye_test = 1 /(1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fase de decisão "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "thresholds = np.arange(0, 1.01, 0.1)\n",
    "confusion_matrix_array = np.zeros((len(thresholds), 2 ,2))\n",
    "\n",
    "# definindo threshold\n",
    "for i in range(len(thresholds)):\n",
    "    \n",
    "    # Decisão: coloca (decide por) 1 se for maior, c.c. 0\n",
    "    matrix_ye_test_decided = (matrix_ye_test >= thresholds[i]).astype(int)\n",
    "\n",
    "    confusion_matrix_array[i] = confusion_matrix(matrix_y_test, matrix_ye_test_decided)\n",
    "\n",
    "confusion_matrix_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**from sklearn import metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "fpr, tpr, n_thresholds = metrics.roc_curve(matrix_y_test, matrix_ye_test)\n",
    "\n",
    "_= plt.plot(fpr, tpr, '.--', label=\"Classificador\");\n",
    "_= plt.title(\"Receiver operating curve - ROC\");\n",
    "_= plt.xlabel(\"false positive - %\");\n",
    "_= plt.ylabel(\"recall - true positive - %\");\n",
    "_= plt.legend();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**na mão**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curva ROC\n",
    "# x - falso positivo (fp / tn + fp ) = (fp / N-) \n",
    "# y - recall - sensibilidade (tp / tp + fn) - true positive\n",
    "pe_ = confusion_matrix_array[:, 0,1]/(confusion_matrix_array[:, 0,0] + confusion_matrix_array[:, 0,1])\n",
    "recall = confusion_matrix_array[:, 1,1]/(confusion_matrix_array[:, 1,1] + confusion_matrix_array[:, 1,0])\n",
    "\n",
    "plt.plot(pe_, recall, '.--');\n",
    "plt.title(\"Receiver operating curve - ROC\");\n",
    "plt.xlabel(\"false positive - %\");\n",
    "plt.ylabel(\"recall - true positive - %\");\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F-score \n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/400px-Precisionrecall.svg.png\"\n",
    "     alt=\"F-score\"\n",
    "     style=\"float: left; margin-right: 400px;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proporção de padrões da classe positiva corretamente classificados em \n",
    "# relação a todos os exemplos atribuídos à classe positiva.\n",
    "precision = confusion_matrix_array[:, 1,1]/np.clip(confusion_matrix_array[:, 1,1] + confusion_matrix_array[:, 0,1], 1e-12, None)\n",
    "\n",
    "# Do total de verdadeiro positivo - Proporção de amostras da classe positiva corretamente classificadas. \n",
    "recall = confusion_matrix_array[:, 1,1]/np.clip(confusion_matrix_array[:, 1,1] + confusion_matrix_array[:, 1,0], 1e-12, None)\n",
    "\n",
    "pd.DataFrame({\"precisao\": precision, \"recall\":recall})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workaround para nao dá divisão por zero. O ideal era tratar esses casos separadamente.\n",
    "recall = np.clip(recall, 1e-12, None)\n",
    "precisao = np.clip(precisao, 1e-12, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 1\n",
    "f_score = ((m + 1)*recall*precision)/(recall + m*precision)\n",
    "\n",
    "index_max = np.argmax(np.array(f_score[:-1]))\n",
    "# Workaround zero divido por zero. O ideal era tratar esse caso antes.\n",
    "ax = plt.plot(thresholds[:-1], f_score[:-1], '.--');\n",
    "plt.plot(thresholds[index_max], f_score[index_max], 'X');\n",
    "plt.annotate(\"Maximum value threshold:\\n\" + str(thresholds[index_max]),\n",
    "            #xy = (matrix_confusion_df['threshold'].iloc[index]/2, f_score.iloc[index]/2))\n",
    "             xy = (0.2, 0.8))\n",
    "plt.title(\"F-score evolution\");\n",
    "plt.xlabel(\"threshold - un\");\n",
    "plt.ylabel(\"F-score - un\");\n",
    "\n",
    "# Para m = 1\n",
    "# Valores  de bem próximos de 1 indicam que o classificador  obteve  \n",
    "# bons resultados tanto na precisão quanto no recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item c \n",
    "\n",
    "Obter matrix de confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " from sklearn.utils.multiclass import unique_labels\n",
    "    \n",
    "plot_confusion_matrix(matrix_y_test.astype(int), (matrix_ye_test >= thresholds[index_max]).astype(int), unique_labels([0,1]));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 2 - Classificação multi-classe\n",
    "\n",
    "Técnica adotada: **Um contra todos**\n",
    "\n",
    "A ideia aqui é fazer 5 classificadores, um para cada classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ler Datasets e converte para float cada entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text_file = open(\"har_smartphone/X_train.txt\", \"r\")\n",
    "# with open(\"har_smartphone/X_train.txt\", \"r\") as my_file:\n",
    "#   for line in my_file:\n",
    "#       row = [float(x) for x in line.split()]\n",
    "#       print(str)\n",
    "\n",
    "X_train = pd.read_fwf('har_smartphone/X_train.txt', header=None)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_fwf('har_smartphone/X_train.txt', header=None)\n",
    "y_train = pd.read_fwf('har_smartphone/y_train.txt', header=None)\n",
    "X_test = pd.read_fwf('har_smartphone/X_test.txt', header=None)\n",
    "y_test = pd.read_fwf('har_smartphone/y_test.txt', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após separar os dataset de treinamento e teste, iremos achar os w dos 5 classificadores usando a estrutura de regressão logística que minimize o critério da função de custo, _cross-entropy_ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix com os atributos\n",
    "matrix_phi = phi(preprocessing.scale(X_train))\n",
    "\n",
    "# matrix com os dados de validação\n",
    "matrix_y = y_train.values\n",
    "\n",
    "# Número de classificadores e seus parâmetros\n",
    "Q = 6\n",
    "matrix_w = np.zeros((Q,X_train.shape[1] + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fase de Treinamento\n",
    "Para achar os ws, os dados de y devem ser transformados. Como será implementada uma classificação um contra todos, para cada iteração q, sendo q igual ao label do Classificador k, k = 0, ... Q-1:\n",
    "* Se q == k, então o label que identifica a classe k passa a ser 1\n",
    "* Se q != k, então o label que identifica a classe k passa a ser 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, axs = plt.subplots(2, 3, constrained_layout=True)\n",
    "\n",
    "for q in range (Q):\n",
    "    # Se for classe q, label -> 1, cc label -> 0\n",
    "    matrix_y_tranform = (matrix_y == q + 1).astype(int)\n",
    "    w, df_cost = find_w(matrix_y_tranform, matrix_phi, 0.01, 1000)\n",
    "    matrix_w[q,:] = np.array(w)[:,0]\n",
    "    _ = axs[q//3, q%3].set_title(\"Classificador para classe: \" + str(q))\n",
    "    _ = df_cost.plot(ax=axs[q//3, q%3], figsize=(10, 10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fase de Teste\n",
    "Calcular a estimativa em cada classificador com os dados de teste\n",
    "\n",
    "Matriz w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix com os atributos\n",
    "matrix_phi_test = phi(preprocessing.scale(X_test))\n",
    "\n",
    "# matrix com os dados de teste mais 1, para nao deixar nenhum nulo\n",
    "matrix_y_test = y_test.values\n",
    "\n",
    "# calculando estimativa para todos os dados de teste com o w calculado anteriormente\n",
    "matrix_ye_test = np.zeros((matrix_y_test.shape[0], Q))\n",
    "for q in range(Q):\n",
    "    z = matrix_phi_test.dot(matrix_w[q])\n",
    "    matrix_ye_test[:, q] = 1 /(1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(matrix_ye_test)\n",
    "pd.DataFrame(matrix_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fase de Decisão\n",
    "\n",
    "Calculando matriz de confusão para cada threshold \n",
    "**sem toolbox**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_ye_test_decided = np.zeros((matrix_y_test.shape[0], Q))\n",
    "\n",
    "#thresholds = np.arange(0, 1.01, 0.1)\n",
    "\n",
    "index = pd.MultiIndex.from_product([range(Q), thresholds], names=['classificador', 'threshold'])\n",
    "matrix_confusion_df = pd.DataFrame(columns=['tp', 'tn', 'fp', 'fn'], index=index)\n",
    "\n",
    "for q in range(Q):\n",
    "    # definindo threshold\n",
    "    for threshold in thresholds:\n",
    "\n",
    "        # Decisão: coloca (decide por) 1 se for maior, c.c. 0\n",
    "        matrix_ye_test_decided[:, q] = (matrix_ye_test[:, q] >= threshold).astype(int)\n",
    "\n",
    "        matrix_confusion = [{'tp':0, 'tn':0, 'fp':0, 'fn':0}]\n",
    "        row_df = pd.DataFrame(matrix_confusion)\n",
    "\n",
    "        #matrix_y_test.T, matrix_ye_test.T\n",
    "\n",
    "        for y, ye in zip((matrix_y_test == q + 1).astype(int), matrix_ye_test_decided[:, q]):\n",
    "            if(y == ye):\n",
    "                if(y == 1):\n",
    "                    row_df[\"tp\"] =  row_df[\"tp\"] + 1\n",
    "                else:\n",
    "                    row_df[\"tn\"] =  row_df[\"tn\"] + 1\n",
    "            else:\n",
    "                if(y == 1):\n",
    "                    # ye == 0, porem y == 0\n",
    "                    row_df[\"fn\"] =  row_df[\"fn\"] + 1\n",
    "                else:\n",
    "                    # ye == 1, porem y == 0\n",
    "                    row_df[\"fp\"] =  row_df[\"fp\"] + 1\n",
    "\n",
    "        matrix_confusion_df.loc[q, threshold] = row_df.iloc[0]\n",
    "\n",
    "matrix_confusion_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculando matriz de confusão para cada threshold **com toolbox**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_ye_test_decided = np.zeros((matrix_y_test.shape[0], Q))\n",
    "cm_one_against_rest_array = np.zeros((Q, len(thresholds), 2, 2))\n",
    "\n",
    "for q in range(Q):\n",
    "    for i in range(len(thresholds)):\n",
    "        \n",
    "        # Decisão: coloca (decide por) 1 se for maior, c.c. 0\n",
    "        matrix_ye_test_decided[:, q] = (matrix_ye_test[:, q] >= thresholds[i]).astype(int)\n",
    "        \n",
    "        # Matriz de confusão\n",
    "        cm_one_against_rest_array[q,i] = confusion_matrix((matrix_y_test == q + 1).astype(int), matrix_ye_test_decided[:, q])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC\n",
    "Com toolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "for q in range (Q):\n",
    "    # Decisão: coloca (decide por) 1 se for maior, c.c. 0\n",
    "    fpr, tpr, n_thresholds = metrics.roc_curve((matrix_y_test == q + 1).astype(int), matrix_ye_test[:, q])\n",
    "    \n",
    "    _ = plt.plot(fpr, tpr, '.--', label=\"Classificador \" + str(q));\n",
    "    _ = plt.title(\"Receiver operating curve - ROC\");\n",
    "    _ = plt.xlabel(\"false positive - %\");\n",
    "    _ = plt.ylabel(\"recall - true positive - %\");\n",
    "    _ = plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 0\n",
    "cm_one_against_rest_array[q, :,0,1]/(cm_one_against_rest_array[q, :,0,0] + cm_one_against_rest_array[q, :,0,1])\n",
    "cm_one_against_rest_array[q, :,1,1]/(cm_one_against_rest_array[q, :,1,1] + cm_one_against_rest_array[q, :,1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sem toolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curva ROC\n",
    "# x - falso positivo (fp / tn + fp ) = (fp / N-) \n",
    "# y - recall - sensibilidade (tp / tp + fn) - true positive\n",
    "#from IPython.core.debugger import set_trace\n",
    "#%debug\n",
    "for q in range (Q):\n",
    "    pe_ = cm_one_against_rest_array[q, :,0,1]/(cm_one_against_rest_array[q, :,0,0] + cm_one_against_rest_array[q, :,0,1])\n",
    "    recall = cm_one_against_rest_array[q, :,1,1]/(cm_one_against_rest_array[q, :,1,1] + cm_one_against_rest_array[q, :,1,0])\n",
    "    #set_trace()\n",
    "    _ = plt.plot(pe_, recall, '.--', label=\"Classificador \" + str(q));\n",
    "    _ = plt.title(\"Receiver operating curve - ROC\");\n",
    "    _ = plt.xlabel(\"false positive - %\");\n",
    "    _ = plt.ylabel(\"recall - true positive - %\");\n",
    "    _ = plt.legend();\n",
    "\n",
    "_ = plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curva ROC\n",
    "# x - falso positivo (fp / tn + fp ) = (fp / N-) \n",
    "# y - recall - sensibilidade (tp / tp + fn) - true positive\n",
    "for q in range (Q):\n",
    "    pe_ = matrix_confusion_df.loc[q]['fp']/(matrix_confusion_df.loc[q]['tn'] + matrix_confusion_df.loc[q]['fp'])\n",
    "    recall = matrix_confusion_df.loc[q]['tp']/(matrix_confusion_df.loc[q]['tp'] + matrix_confusion_df.loc[q]['fn'])\n",
    "\n",
    "    _ = plt.plot(pe_, recall, '.--', label=\"Classificador \" + str(q));\n",
    "    _ = plt.title(\"Receiver operating curve - ROC\");\n",
    "    _ = plt.xlabel(\"false positive - %\");\n",
    "    _ = plt.ylabel(\"recall - true positive - %\");\n",
    "    _ = plt.legend();\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_max_array = np.zeros((Q))\n",
    "index_max\n",
    "for q in range(Q):\n",
    "    # Proporção de padrões da classe positiva corretamente classificados em \n",
    "    # relação a todos os exemplos atribuídos à classe positiva.\n",
    "    precision = cm_one_against_rest_array[q, :, 1,1]/np.clip(cm_one_against_rest_array[q, :, 1,1] + cm_one_against_rest_array[q, :, 0,1], 1e-12, None)\n",
    "\n",
    "    # Do total de verdadeiro positivo - Proporção de amostras da classe positiva corretamente classificadas. \n",
    "    recall = cm_one_against_rest_array[q, :, 1,1]/np.clip(cm_one_against_rest_array[q, :, 1,1] + cm_one_against_rest_array[q, :, 1,0], 1e-12, None)\n",
    "\n",
    "    # Workaround para nao dá divisão por zero. O ideal era tratar esses casos separadamente.\n",
    "    recall = np.clip(recall, 1e-12, None)\n",
    "    precision = np.clip(precision, 1e-12, None)\n",
    "\n",
    "    m = 1\n",
    "    f_score = ((m + 1)*recall*precision)/(recall + m*precision)\n",
    "\n",
    "    # Pega o index do F-score máximo.\n",
    "    index_max = np.argmax(np.array(f_score[:-1]))\n",
    "    \n",
    "    # Plota removendo os NaN\n",
    "    axs = plt.plot(thresholds[:-1], f_score[:-1], '.--', label=\"Classificador \" + str(q));\n",
    "    _= plt.plot(thresholds[:-1][index_max], f_score[:-1][index_max], 'X', color=axs[0].get_color());\n",
    "    _= plt.title(\"F-score evolution\");\n",
    "    _= plt.xlabel(\"threshold - un\");\n",
    "    _= plt.ylabel(\"F-score - un\");\n",
    "    _= plt.legend()\n",
    "    \n",
    "    index_max_array[q] = index_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_max_array"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
